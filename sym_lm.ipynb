{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:23:52.152506Z",
     "iopub.status.busy": "2023-09-07T06:23:52.151774Z",
     "iopub.status.idle": "2023-09-07T06:23:53.318709Z",
     "shell.execute_reply": "2023-09-07T06:23:53.317688Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from models import GPTLanguageModel, SymGPTLanguageModel\n",
    "from utils import get_batch, calculate_cooc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:23:53.324747Z",
     "iopub.status.busy": "2023-09-07T06:23:53.324512Z",
     "iopub.status.idle": "2023-09-07T06:23:53.339983Z",
     "shell.execute_reply": "2023-09-07T06:23:53.339200Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64     # how many independent sequences will we process in parallel?\n",
    "block_size = 32     # 256    # what is the maximum context length for predictions?\n",
    "max_iters = 2000    # 5000\n",
    "eval_interval = 50\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128 # 384\n",
    "n_head = 6  # 6\n",
    "n_layer = 1 # 6\n",
    "dropout = 0.2\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:23:53.344801Z",
     "iopub.status.busy": "2023-09-07T06:23:53.344560Z",
     "iopub.status.idle": "2023-09-07T06:23:53.349559Z",
     "shell.execute_reply": "2023-09-07T06:23:53.348758Z"
    }
   },
   "outputs": [],
   "source": [
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('./data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:23:53.354404Z",
     "iopub.status.busy": "2023-09-07T06:23:53.354125Z",
     "iopub.status.idle": "2023-09-07T06:23:53.442070Z",
     "shell.execute_reply": "2023-09-07T06:23:53.441224Z"
    }
   },
   "outputs": [],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "data_dict = {'train': train_data, 'val': val_data}\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(data_dict, split, block_size, batch_size, device)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic Attention Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:23:53.448330Z",
     "iopub.status.busy": "2023-09-07T06:23:53.448150Z",
     "iopub.status.idle": "2023-09-07T06:25:38.886468Z",
     "shell.execute_reply": "2023-09-07T06:25:38.885423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cooc = calculate_cooc(data_dict['train'], vocab_size, n_head, device=device)\n",
    "for h in range(n_head):\n",
    "    # print(\"{}-cooc:\\n{}\\n\".format(h+1, cooc[:,:,h]))\n",
    "    plt.imshow(cooc[:,:,h].cpu().numpy())\n",
    "    plt.savefig('./figs/{}-cooc.png'.format(h+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:25:38.944092Z",
     "iopub.status.busy": "2023-09-07T06:25:38.943718Z",
     "iopub.status.idle": "2023-09-07T06:42:05.300106Z",
     "shell.execute_reply": "2023-09-07T06:42:05.299280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From SymbolicMultiHeadAttention: N 65, K 6, hs 390, embedding_dim 128\n",
      "0.592357 M parameters\n",
      "Model:  SymGPTLanguageModel(\n",
      "  (blocks): Sequential(\n",
      "    (0): SymbolicBlock(\n",
      "      (sa): SymbolicMultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0): SymbolicAttentionHead(\n",
      "            (value): Embedding(65, 390)\n",
      "          )\n",
      "          (1): SymbolicAttentionHead(\n",
      "            (value): Embedding(65, 390)\n",
      "          )\n",
      "          (2): SymbolicAttentionHead(\n",
      "            (value): Embedding(65, 390)\n",
      "          )\n",
      "          (3): SymbolicAttentionHead(\n",
      "            (value): Embedding(65, 390)\n",
      "          )\n",
      "          (4): SymbolicAttentionHead(\n",
      "            (value): Embedding(65, 390)\n",
      "          )\n",
      "          (5): SymbolicAttentionHead(\n",
      "            (value): Embedding(65, 390)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=2340, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=128, out_features=65, bias=True)\n",
      ")\n",
      "step 0: train loss 4.1154, val loss 4.1157\n",
      "step 50: train loss 3.1189, val loss 3.1437\n",
      "step 100: train loss 2.8477, val loss 2.8624\n",
      "step 150: train loss 2.7396, val loss 2.7386\n",
      "step 200: train loss 2.6996, val loss 2.7008\n",
      "step 250: train loss 2.6586, val loss 2.6576\n",
      "step 300: train loss 2.6458, val loss 2.6490\n",
      "step 350: train loss 2.6386, val loss 2.6473\n",
      "step 400: train loss 2.6216, val loss 2.6246\n",
      "step 450: train loss 2.6158, val loss 2.6276\n",
      "step 500: train loss 2.6133, val loss 2.6177\n",
      "step 550: train loss 2.6091, val loss 2.6163\n",
      "step 600: train loss 2.6149, val loss 2.6278\n",
      "step 650: train loss 2.6016, val loss 2.6110\n",
      "step 700: train loss 2.6081, val loss 2.6189\n",
      "step 750: train loss 2.6029, val loss 2.6106\n",
      "step 800: train loss 2.5929, val loss 2.6093\n",
      "step 850: train loss 2.6062, val loss 2.6228\n",
      "step 900: train loss 2.5821, val loss 2.5956\n",
      "step 950: train loss 2.5806, val loss 2.5983\n",
      "step 1000: train loss 2.5809, val loss 2.5963\n",
      "step 1050: train loss 2.5775, val loss 2.5962\n",
      "step 1100: train loss 2.5819, val loss 2.6043\n",
      "step 1150: train loss 2.5754, val loss 2.5913\n",
      "step 1200: train loss 2.5771, val loss 2.6014\n",
      "step 1250: train loss 2.5692, val loss 2.5868\n",
      "step 1300: train loss 2.5683, val loss 2.5921\n",
      "step 1350: train loss 2.5656, val loss 2.5900\n",
      "step 1400: train loss 2.5748, val loss 2.5889\n",
      "step 1450: train loss 2.5610, val loss 2.5800\n",
      "step 1500: train loss 2.5570, val loss 2.5780\n",
      "step 1550: train loss 2.5635, val loss 2.5820\n",
      "step 1600: train loss 2.5629, val loss 2.5895\n",
      "step 1650: train loss 2.5591, val loss 2.5788\n",
      "step 1700: train loss 2.5708, val loss 2.5935\n",
      "step 1750: train loss 2.5606, val loss 2.5801\n",
      "step 1800: train loss 2.5594, val loss 2.5790\n",
      "step 1850: train loss 2.5690, val loss 2.5858\n",
      "step 1900: train loss 2.5605, val loss 2.5842\n",
      "step 1950: train loss 2.5621, val loss 2.5921\n",
      "step 1999: train loss 2.5597, val loss 2.5770\n"
     ]
    }
   ],
   "source": [
    "model = SymGPTLanguageModel(vocab_size, n_embd, n_head, n_layer, block_size, dropout, device, cooc)  \n",
    "model = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "# print model summary\n",
    "print('Model: ', model)\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# bookkeeping\n",
    "losses_log = dict({'iter': [], 'train': [], 'val': []})\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        losses_log['train'].append(losses['train'].item())\n",
    "        losses_log['val'].append(losses['val'].item())\n",
    "        losses_log['iter'].append(iter)\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(data_dict, 'train', block_size, batch_size, device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# save losses\n",
    "with open('./data/losses_symbolic.json', 'w') as fp:\n",
    "    json.dump(losses_log, fp)\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), './data/gpt_symbolic.pth')\n",
    "\n",
    "# # generate from the model\n",
    "# context = torch.zeros((1), dtype=torch.long, device=device)\n",
    "# # print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "# open('./data/gen_symbolic.txt', 'w').write(decode(model.generate(context, max_new_tokens=10000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:42:05.306966Z",
     "iopub.status.busy": "2023-09-07T06:42:05.306759Z",
     "iopub.status.idle": "2023-09-07T06:42:05.310920Z",
     "shell.execute_reply": "2023-09-07T06:42:05.310211Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Test Example\n",
    "\n",
    "# block_size_t = 4\n",
    "# device_t = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# n_embd_t = 12\n",
    "# n_head_t = 3\n",
    "# n_layer_t = 1\n",
    "# dropout_t = 0.2\n",
    "\n",
    "# text = [0,2,3,1,1,4,2,3,1]\n",
    "# data = torch.tensor(text, dtype=torch.long)\n",
    "# vocab_size_t = len(list(set(text)))\n",
    "# cooc = calculate_cooc(text, vocab_size_t, n_head_t, device=device_t)\n",
    "# # for h in range(n_head_t):\n",
    "# #     print(\"{}-cooc:\\n{}\\n\".format(h+1, cooc[:,:,h]))\n",
    "\n",
    "# # sample a batch of data\n",
    "# batches_anchor = [0, 1]\n",
    "# x = torch.stack([data[i:i+block_size_t] for i in batches_anchor])\n",
    "# y = torch.stack([data[i+1:i+block_size_t+1] for i in batches_anchor])\n",
    "# x, y = x.to(device_t), y.to(device_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:42:05.316529Z",
     "iopub.status.busy": "2023-09-07T06:42:05.316348Z",
     "iopub.status.idle": "2023-09-07T06:43:49.714488Z",
     "shell.execute_reply": "2023-09-07T06:43:49.713531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.217921 M parameters\n",
      "Model:  GPTLanguageModel(\n",
      "  (token_embedding_table): Embedding(65, 128)\n",
      "  (position_embedding_table): Embedding(32, 128)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0): Head(\n",
      "            (key): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (query): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (value): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (1): Head(\n",
      "            (key): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (query): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (value): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (2): Head(\n",
      "            (key): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (query): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (value): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (3): Head(\n",
      "            (key): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (query): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (value): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (4): Head(\n",
      "            (key): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (query): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (value): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (5): Head(\n",
      "            (key): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (query): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (value): Linear(in_features=128, out_features=21, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=126, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=128, out_features=65, bias=True)\n",
      ")\n",
      "step 0: train loss 4.2001, val loss 4.2039\n",
      "step 50: train loss 2.8522, val loss 2.8747\n",
      "step 100: train loss 2.6083, val loss 2.6089\n",
      "step 150: train loss 2.5069, val loss 2.5136\n",
      "step 200: train loss 2.4358, val loss 2.4505\n",
      "step 250: train loss 2.3652, val loss 2.3663\n",
      "step 300: train loss 2.2719, val loss 2.2824\n",
      "step 350: train loss 2.2071, val loss 2.2213\n",
      "step 400: train loss 2.1603, val loss 2.1844\n",
      "step 450: train loss 2.1181, val loss 2.1475\n",
      "step 500: train loss 2.0748, val loss 2.1162\n",
      "step 550: train loss 2.0397, val loss 2.0920\n",
      "step 600: train loss 2.0150, val loss 2.0713\n",
      "step 650: train loss 1.9897, val loss 2.0581\n",
      "step 700: train loss 1.9717, val loss 2.0501\n",
      "step 750: train loss 1.9511, val loss 2.0256\n",
      "step 800: train loss 1.9291, val loss 2.0109\n",
      "step 850: train loss 1.9180, val loss 2.0033\n",
      "step 900: train loss 1.9096, val loss 2.0031\n",
      "step 950: train loss 1.8873, val loss 1.9895\n",
      "step 1000: train loss 1.8753, val loss 1.9841\n",
      "step 1050: train loss 1.8655, val loss 1.9832\n",
      "step 1100: train loss 1.8519, val loss 1.9751\n",
      "step 1150: train loss 1.8446, val loss 1.9673\n",
      "step 1200: train loss 1.8340, val loss 1.9520\n",
      "step 1250: train loss 1.8284, val loss 1.9532\n",
      "step 1300: train loss 1.8159, val loss 1.9412\n",
      "step 1350: train loss 1.8120, val loss 1.9428\n",
      "step 1400: train loss 1.8088, val loss 1.9394\n",
      "step 1450: train loss 1.7975, val loss 1.9222\n",
      "step 1500: train loss 1.7876, val loss 1.9341\n",
      "step 1550: train loss 1.7782, val loss 1.9214\n",
      "step 1600: train loss 1.7765, val loss 1.9159\n",
      "step 1650: train loss 1.7778, val loss 1.9229\n",
      "step 1700: train loss 1.7664, val loss 1.9192\n",
      "step 1750: train loss 1.7608, val loss 1.9216\n",
      "step 1800: train loss 1.7579, val loss 1.9105\n",
      "step 1850: train loss 1.7548, val loss 1.9226\n",
      "step 1900: train loss 1.7507, val loss 1.9018\n",
      "step 1950: train loss 1.7437, val loss 1.8986\n",
      "step 1999: train loss 1.7365, val loss 1.9007\n"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel(vocab_size, n_embd, n_head, n_layer, block_size, dropout, device)\n",
    "model = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "# print model summary\n",
    "print('Model: ', model)\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# bookkeeping\n",
    "losses_log = dict({'iter': [], 'train': [], 'val': []})\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        losses_log['train'].append(losses['train'].item())\n",
    "        losses_log['val'].append(losses['val'].item())\n",
    "        losses_log['iter'].append(iter)\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(data_dict, 'train', block_size, batch_size, device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# save losses\n",
    "with open('./data/losses_original.json', 'w') as fp:\n",
    "    json.dump(losses_log, fp)\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), './data/gpt_original.pth')\n",
    "\n",
    "# generate from the model\n",
    "# context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "# print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "# open('./data/gen_original.txt', 'w').write(decode(model.generate(context, max_new_tokens=10000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Reshaping and Slicing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T06:43:49.721857Z",
     "iopub.status.busy": "2023-09-07T06:43:49.721482Z",
     "iopub.status.idle": "2023-09-07T06:43:49.731856Z",
     "shell.execute_reply": "2023-09-07T06:43:49.731252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-cooc:\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "\n",
      "2-cooc:\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "\n",
      "3-cooc:\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "\n",
      "tensor([0., 0., 0., 1., 1., 1.])\n",
      "tensor([2., 2., 2., 3., 3., 3.])\n",
      "tensor([2., 0., 3.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,2,3)\n",
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        a[i,j,0] = 2*i + j\n",
    "        a[i,j,1] = 2*i + j\n",
    "        a[i,j,2] = 2*i + j\n",
    "for k in [0,1,2]:\n",
    "    print(\"{}-cooc:\\n{}\\n\".format(k+1, a[:,:,k]))\n",
    "\n",
    "af = torch.flatten(a, start_dim=1)\n",
    "for i in [0,1]:\n",
    "    print(af[i])\n",
    "\n",
    "index = torch.tensor([[1,1],[0,0],[1,3]])\n",
    "ind = index[:,0] * af.size(1) + index[:,1]\n",
    "print(torch.take(af, ind))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('neuro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "45a9a558b30b86d9f732c54dbfd32f3dc135cf8debc1699b6136107345de1818"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
